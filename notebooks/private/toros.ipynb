{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from api.internal_api import SynthetixAPI, get_db_config\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# constants\n",
    "PROTOCOL = \"toros\"\n",
    "DATA_LOC = \"~/repos/data/parquet-data/indexers\"\n",
    "db_config = get_db_config(streamlit=False)\n",
    "api = SynthetixAPI(db_config, streamlit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry fee\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_entry_fee_minted.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_entry_fee = df.to_pandas()\n",
    "\n",
    "# exit fee\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_exit_fee_minted.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_exit_fee = df.to_pandas()\n",
    "\n",
    "# withdrawals\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_withdrawal_initiated.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_wd_init = df.to_pandas()\n",
    "\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_withdrawal_completed.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_wd_complete = df.to_pandas()\n",
    "\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_withdrawal.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_wd = df.to_pandas()\n",
    "\n",
    "# deposits\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_deposit.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_deposit = df.to_pandas()\n",
    "\n",
    "# manager fee\n",
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/*_event_manager_fee_minted.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_manager_fee = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl = pl.scan_parquet(\n",
    "    [\n",
    "        f\"{DATA_LOC}/raw/optimism_mainnet/{PROTOCOL}/**/transaction.parquet\",\n",
    "    ],\n",
    "    include_file_paths=\"file_location\",\n",
    ")\n",
    "df = df_pl.collect()\n",
    "df_tx = df.to_pandas()\n",
    "\n",
    "df_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manager_fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis plan:\n",
    "\n",
    "- get all unique withdrawal initiated and completed transaction hashes, with the depositor/withdrawer address\n",
    "- get all unique deposit transaction hashes, with the depositor/withdrawer address\n",
    "- combine all manager entry and exit fees into a single dataframe\n",
    "- combine withdrawal and deposit dataframes\n",
    "- join the address from the deposit/withdrawals to the fee dataframe to determine who paid those fees\n",
    "- Summarize this by depositor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entry_fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withdrawal_txs = pd.concat(\n",
    "    [\n",
    "        df_wd_init[[\"transactionHash\", \"depositor\", \"blockTimestamp\"]].rename(\n",
    "            columns={\"depositor\": \"address\"}\n",
    "        ),\n",
    "        df_wd_complete[[\"transactionHash\", \"depositor\", \"blockTimestamp\"]].rename(\n",
    "            columns={\"depositor\": \"address\"}\n",
    "        ),\n",
    "        df_wd[[\"transactionHash\", \"investor\", \"blockTimestamp\"]].rename(\n",
    "            columns={\"investor\": \"address\"}\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "withdrawal_txs = withdrawal_txs.drop_duplicates(\"transactionHash\")\n",
    "\n",
    "# Get unique deposit transactions with investor info\n",
    "deposit_txs = df_deposit[[\"transactionHash\", \"investor\", \"blockTimestamp\"]].rename(\n",
    "    columns={\"investor\": \"address\"}\n",
    ")\n",
    "deposit_txs = deposit_txs.drop_duplicates(\"transactionHash\")\n",
    "\n",
    "# Combine all transactions into single dataframe\n",
    "all_txs = pd.concat(\n",
    "    [withdrawal_txs.assign(tx_type=\"withdrawal\"), deposit_txs.assign(tx_type=\"deposit\")]\n",
    ")\n",
    "\n",
    "# Combine entry and exit fees\n",
    "df_manager_fee[\"fees\"] = df_manager_fee[\"daoFee\"].apply(\n",
    "    lambda x: int(x) / 1e18\n",
    ") + df_manager_fee[\"managerFee\"].apply(lambda x: int(x) / 1e18)\n",
    "df_entry_fee[\"fees\"] = df_entry_fee[\"entryFeeAmount\"].apply(lambda x: int(x) / 1e18)\n",
    "df_exit_fee[\"fees\"] = df_exit_fee[\"exitFeeAmount\"].apply(lambda x: int(x) / 1e18)\n",
    "all_fees = pd.concat(\n",
    "    [\n",
    "        df_entry_fee[[\"transactionHash\", \"fees\", \"file_location\"]].assign(\n",
    "            fee_type=\"entry\"\n",
    "        ),\n",
    "        df_exit_fee[[\"transactionHash\", \"fees\", \"file_location\"]].assign(\n",
    "            fee_type=\"exit\"\n",
    "        ),\n",
    "        df_manager_fee[[\"transactionHash\", \"fees\", \"file_location\"]].assign(\n",
    "            fee_type=\"manager\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Join fees with transaction data to get user addresses\n",
    "fees_with_users = pd.merge(all_fees, all_txs, on=\"transactionHash\", how=\"left\")\n",
    "# fees_with_users[\"file_location\"][0]\n",
    "# returns: '/Users/Troy/repos/data/parquet-data/indexers/raw/optimism_mainnet/toros/0128343148-0128780000/btc_bear1_x_event_entry_fee_minted.parquet'\n",
    "# parse into just `BTC_BEAR_1x`\n",
    "fees_with_users[\"token\"] = fees_with_users[\"file_location\"].apply(\n",
    "    lambda x: \"\".join(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:2])\n",
    ")\n",
    "\n",
    "# Group by address and summarize fees\n",
    "fee_summary = (\n",
    "    fees_with_users.groupby([\"token\", \"address\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"fees\": \"sum\",\n",
    "            \"transactionHash\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    .round(6)\n",
    ")\n",
    "\n",
    "fee_summary = fee_summary.reset_index().sort_values(\"fees\", ascending=False)\n",
    "fee_summary = fee_summary.rename(columns={\"transactionHash\": \"num_transactions\"})\n",
    "\n",
    "# Also calculate total fees per user\n",
    "total_fees = (\n",
    "    fees_with_users.groupby(\"address\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"fees\": \"sum\",\n",
    "            \"transactionHash\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    .round(6)\n",
    ")\n",
    "\n",
    "total_fees = total_fees.reset_index().sort_values(\"fees\", ascending=False)\n",
    "total_fees = total_fees.rename(columns={\"transactionHash\": \"total_transactions\"})\n",
    "\n",
    "print(\"\\nTop 10 users by total fees paid:\")\n",
    "print(total_fees.sort_values(\"fees\", ascending=False).head(25))\n",
    "\n",
    "print(\"\\nFee breakdown by type for top users:\")\n",
    "print(\n",
    "    fee_summary[fee_summary[\"address\"].isin(total_fees.nlargest(25, \"fees\")[\"address\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "fee_summary.to_csv(\"fee_summary.csv\", index=False)\n",
    "total_fees.head(25).to_csv(\"total_fees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a check. Get total fees from the fees table and compare to the sum of entry, exit, and manager fees\n",
    "total_fees_check = (\n",
    "    fees_with_users.groupby(\"fee_type\").agg({\"fees\": \"sum\"}).reset_index()\n",
    ")\n",
    "print(total_fees_check)\n",
    "\n",
    "# get total fees from the summary\n",
    "total_fees_check = fee_summary.groupby(\"fee_type\").agg({\"fees\": \"sum\"}).reset_index()\n",
    "print(total_fees_check)\n",
    "\n",
    "# get the total from the raw dataframes\n",
    "print(df_entry_fee[\"entryFeeAmount\"].apply(lambda x: int(x) / 1e18).sum())\n",
    "print(df_exit_fee[\"exitFeeAmount\"].apply(lambda x: int(x) / 1e18).sum())\n",
    "print(df_manager_fee[\"daoFee\"].apply(lambda x: int(x) / 1e18).sum())\n",
    "print(df_manager_fee[\"managerFee\"].apply(lambda x: int(x) / 1e18).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-tools-aFHH3xsL-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
